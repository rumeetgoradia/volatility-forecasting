data:
  raw_path: "data/raw/futures_data.parquet"
  processed_path: "data/processed/"
  regimes_path: "data/regimes/"

  instruments:
    - "INDX.CAC"
    - "INDX.SPX"
    - "INDX.TPX"
    - "INDX.UKX"
    - "INDX.NDX"
    - "INDX.FTSEMIB"
    - "INDX.SMI"

  split:
    train_start: "2000-01-01"
    train_end: "2018-12-31"
    val_start: "2019-01-01"
    val_end: "2021-12-31"
    test_start: "2022-01-01"
    test_end: "2025-04-30"

preprocessing:
  remove_zero_volume: true
  outlier_threshold: 0.05

features:
  intraday:
    rv_windows_minutes: [30, 120, 240]
    rq_windows_minutes: [60, 240]
    vol_corr_windows_minutes: [60, 240]

models:
  har_rv:
    alpha: 0.01
    positive: true

  lstm:
    hidden_size: 64
    num_layers: 2
    dropout: 0.2
    sequence_length: 20
    batch_size: 64
    learning_rate: 0.001
    epochs: 50
    patience: 10

  tcn:
    kernel_size: 3
    dropout: 0.2
    sequence_length: 20
    batch_size: 64
    learning_rate: 0.001
    epochs: 50
    patience: 10

regimes:
  method: "hmm"
  n_regimes: 3
  features:
    - "RV_H1"
    - "RV_H6"
    - "volume_log"
    - "RV_30m"
    - "RV_120m"

  hmm:
    n_components: 3
    covariance_type: "full"
    n_iter: 100
    random_state: 42

ensemble:
  experts:
    - "har_rv"
    - "lstm"
    - "tcn"
    - "timesfm_fintext_finetune_full"
  regime_weights:
    0:
      har_rv: 0.20
      lstm: 0.30
      tcn: 0.30
      timesfm_fintext_finetune_full: 0.20
    1:
      har_rv: 0.40
      lstm: 0.20
      tcn: 0.20
      timesfm_fintext_finetune_full: 0.20
    2:
      har_rv: 0.30
      lstm: 0.10
      tcn: 0.10
      timesfm_fintext_finetune_full: 0.50
  # regime_weights:
  #   0:
  #     har_rv: 1
  #     lstm: 0
  #     tcn: 0
  #     timesfm_fintext_finetune_full: 0
  #   1:
  #     har_rv: 1
  #     lstm: 0
  #     tcn: 0
  #     timesfm_fintext_finetune_full: 0
  #   2:
  #     har_rv: 1
  #     lstm: 0
  #     tcn: 0
  #     timesfm_fintext_finetune_full: 0

target:
  bar_minutes: 5
  horizon_minutes: 60
  target_col: "RV_1H"
  har_windows: [1, 6, 24]
  hourly_minute: 55

chronos_fintext:
  model_id: "FinText/Chronos_Tiny_2018_Global"
  bar_minutes: 5
  context_bars: 336
  prediction_length: 1
  input_series: "RV_1H"
  input_representation: "rv"
  pred_floor: 0.0001
  num_samples: 50
  reduce: "median"
  device_map: "auto"
  torch_dtype: "auto"
  progress_file: "outputs/progress/chronos_fintext_training.json"

timesfm_fintext:
  model_id: "FinText/TimesFM_8M_2018_Global"
  bar_minutes: 5
  context_bars: 120
  prediction_length: 1
  frequency_id: 0
  input_series: "RV_1H"
  input_representation: "rv"
  pred_floor: 0.0001
  dyn_floor_factor: 0.0
  log_scale: true
  calibrate: false
  truncate_negative: false
  device_map: "auto"
  torch_dtype: "auto"
  progress_file: "outputs/progress/timesfm_fintext_training.json"
  progress_file_finetune: "outputs/progress/timesfm_fintext_finetune_progress.json"

  # Fine-tune options
  finetune_mode: "full" # "full"
  finetune_epochs: 10
  finetune_batch_size: 32
  finetune_lr: 0.0001
  finetune_min_lr: 0.0001
  finetune_weight_decay: 0.01
  finetune_max_grad_norm: 1.0
  finetune_ema_decay: 1.0
  finetune_internal_val_frac: 0.0
  finetune_early_stopping_patience: 5
  finetune_output_suffix: "full"  # optional suffix for predictions/results/progress; defaults to finetune_mode when null

random_seed: 42
